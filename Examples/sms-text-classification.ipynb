{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>SMS Text classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Import\" data-toc-modified-id=\"Data-Import-1\">Data Import</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-some-functions\" data-toc-modified-id=\"Define-some-functions-1.1\">Define some functions</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\">Preprocessing</a></span></li><li><span><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-3\">Feature Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Word-Count\" data-toc-modified-id=\"Word-Count-3.1\">Word Count</a></span></li><li><span><a href=\"#Tf-Idf\" data-toc-modified-id=\"Tf-Idf-3.2\">Tf-Idf</a></span></li><li><span><a href=\"#N-gram\" data-toc-modified-id=\"N-gram-3.3\">N-gram</a></span></li></ul></li><li><span><a href=\"#Text-Classification\" data-toc-modified-id=\"Text-Classification-4\">Text Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-4.1\"><a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering\" target=\"_blank\">Naive Bayes</a></a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-4.2\">SVM</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-4.3\">LogisticRegression</a></span></li><li><span><a href=\"#GBDT\" data-toc-modified-id=\"GBDT-4.4\">GBDT</a></span></li></ul></li><li><span><a href=\"#word2vec\" data-toc-modified-id=\"word2vec-5\">word2vec</a></span></li><li><span><a href=\"#Bert-TensorFlow\" data-toc-modified-id=\"Bert-TensorFlow-6\">Bert-TensorFlow</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set_style('white') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv')\n",
    "#stopword_list = [k.strip() for k in open(\"E:/MaLearning/souhu/stopwords.txt\", encoding='utf8').readlines() if k.strip() != '']\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Category\"] = data[\"Category\"].map({'ham': 0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Feature Extraction\n",
    "\n",
    "There is several ways to extract features from text data, including word count method and tf-idf encoding. Now I will do both of them and compare their effect of predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for article in data[\"Message\"]:\n",
    "    article = re.sub(\"[^a-zA-Z]\",\" \",article)\n",
    "    article = article.lower()   # low case letter\n",
    "    article = word_tokenize(article)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    article = [ lemma.lemmatize(word) for word in article]\n",
    "    article = \" \".join(article)\n",
    "    description_list.append(article) #we hide all word one section\n",
    "    \n",
    "    \n",
    "def text_replace(text):\n",
    "    '''some text cleaning method'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://i.loli.net/2019/11/18/kdH1gfSlezstUwL.png\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Word Count Vectorizer</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features = 100, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "tokens = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amp</th>\n",
       "      <th>ask</th>\n",
       "      <th>babe</th>\n",
       "      <th>care</th>\n",
       "      <th>cash</th>\n",
       "      <th>claim</th>\n",
       "      <th>com</th>\n",
       "      <th>come</th>\n",
       "      <th>contact</th>\n",
       "      <th>da</th>\n",
       "      <th>...</th>\n",
       "      <th>wat</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>win</th>\n",
       "      <th>won</th>\n",
       "      <th>work</th>\n",
       "      <th>www</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amp  ask  babe  care  cash  claim  com  come  contact  da  ...  wat  way  \\\n",
       "0    0    0     0     0     0      0    0     0        0   0  ...    1    0   \n",
       "1    0    0     0     0     0      0    0     0        0   0  ...    0    0   \n",
       "2    0    0     0     0     0      0    0     0        0   0  ...    0    0   \n",
       "3    0    0     0     0     0      0    0     0        0   0  ...    0    0   \n",
       "4    0    0     0     0     0      0    0     0        0   0  ...    0    0   \n",
       "\n",
       "   week  win  won  work  www  yeah  year  yes  \n",
       "0     0    0    0     0    0     0     0    0  \n",
       "1     0    0    0     0    0     0     0    0  \n",
       "2     0    1    0     0    0     0     0    0  \n",
       "3     0    0    0     0    0     0     0    0  \n",
       "4     0    0    0     0    0     0     0    0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sparce_matrix))\n",
    "sparce_matrix = pd.DataFrame(sparce_matrix, columns=tokens)\n",
    "sparce_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf\n",
    "\n",
    " Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>all</th>\n",
       "      <th>am</th>\n",
       "      <th>and</th>\n",
       "      <th>any</th>\n",
       "      <th>are</th>\n",
       "      <th>at</th>\n",
       "      <th>back</th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>wa</th>\n",
       "      <th>want</th>\n",
       "      <th>we</th>\n",
       "      <th>week</th>\n",
       "      <th>what</th>\n",
       "      <th>when</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  all   am  and  any  are   at  back   be  but  ...   wa  want   we  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0   0.0  0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0   0.0  0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0   0.0  0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0   0.0  0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  ...  0.0   0.0  0.0   \n",
       "\n",
       "   week  what  when  will  with  you  your  \n",
       "0   0.0   0.0   0.0   0.0   0.0  0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 100)\n",
    "tfidfmatrix = vectorizer.fit_transform(description_list)\n",
    "cname = vectorizer.get_feature_names()\n",
    "tfidfmatrix = pd.DataFrame(tfidfmatrix.toarray(),columns=cname)\n",
    "tfidfmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['about', 'all', 'am', 'and', 'any', 'are', 'at', 'back', 'be', 'but',\n",
       "       'by', 'call', 'can', 'come', 'da', 'day', 'do', 'don', 'dont', 'for',\n",
       "       'free', 'from', 'get', 'go', 'going', 'good', 'got', 'gt', 'ha', 'have',\n",
       "       'he', 'her', 'hi', 'home', 'how', 'if', 'in', 'is', 'it', 'just',\n",
       "       'know', 'later', 'like', 'll', 'lor', 'love', 'lt', 'me', 'mobile',\n",
       "       'my', 'need', 'new', 'no', 'not', 'now', 'of', 'ok', 'on', 'one',\n",
       "       'only', 'or', 'our', 'out', 'phone', 'please', 'pls', 'reply', 'see',\n",
       "       'send', 'she', 'so', 'sorry', 'still', 'stop', 'take', 'tell', 'text',\n",
       "       'that', 'the', 'then', 'there', 'they', 'think', 'this', 'time', 'to',\n",
       "       'today', 'txt', 'up', 'ur', 'wa', 'want', 'we', 'week', 'what', 'when',\n",
       "       'will', 'with', 'you', 'your'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfmatrix.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account statement</th>\n",
       "      <th>attempt contact</th>\n",
       "      <th>await collection</th>\n",
       "      <th>camcorder reply</th>\n",
       "      <th>camera phone</th>\n",
       "      <th>cash prize</th>\n",
       "      <th>chance win</th>\n",
       "      <th>claim code</th>\n",
       "      <th>claim ur</th>\n",
       "      <th>claim valid</th>\n",
       "      <th>...</th>\n",
       "      <th>urgent mobile</th>\n",
       "      <th>valid hr</th>\n",
       "      <th>wan na</th>\n",
       "      <th>want come</th>\n",
       "      <th>want new</th>\n",
       "      <th>wat doing</th>\n",
       "      <th>wat time</th>\n",
       "      <th>week just</th>\n",
       "      <th>won guaranteed</th>\n",
       "      <th>won prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   account statement  attempt contact  await collection  camcorder reply  \\\n",
       "0                  0                0                 0                0   \n",
       "1                  0                0                 0                0   \n",
       "2                  0                0                 0                0   \n",
       "3                  0                0                 0                0   \n",
       "4                  0                0                 0                0   \n",
       "\n",
       "   camera phone  cash prize  chance win  claim code  claim ur  claim valid  \\\n",
       "0             0           0           0           0         0            0   \n",
       "1             0           0           0           0         0            0   \n",
       "2             0           0           0           0         0            0   \n",
       "3             0           0           0           0         0            0   \n",
       "4             0           0           0           0         0            0   \n",
       "\n",
       "   ...  urgent mobile  valid hr  wan na  want come  want new  wat doing  \\\n",
       "0  ...              0         0       0          0         0          0   \n",
       "1  ...              0         0       0          0         0          0   \n",
       "2  ...              0         0       0          0         0          0   \n",
       "3  ...              0         0       0          0         0          0   \n",
       "4  ...              0         0       0          0         0          0   \n",
       "\n",
       "   wat time  week just  won guaranteed  won prize  \n",
       "0         0          0               0          0  \n",
       "1         0          0               0          0  \n",
       "2         0          0               0          0  \n",
       "3         0          0               0          0  \n",
       "4         0          0               0          0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_features = 100, stop_words = \"english\",ngram_range=(2, 2),)\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "tokens = count_vectorizer.get_feature_names()\n",
    "gram2 = pd.DataFrame(sparce_matrix, columns=tokens)\n",
    "gram2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering)\n",
    "\n",
    "Naive Bayes gives us a baseline accuracy of predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = data.iloc[:,0].values   \n",
    "x = sparce_matrix\n",
    "tfidfx = tfidfmatrix\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 2019)\n",
    "tf_x_train, tf_x_test, tf_y_train, tf_y_test = train_test_split(tfidfmatrix ,y,\n",
    "                                                                test_size = 0.3,\n",
    "                                                                random_state = 2019)\n",
    "\n",
    "gm_x_train, gm_x_test, gm_y_train, gm_y_test = train_test_split(gram2 ,y,\n",
    "                                                                test_size = 0.3,\n",
    "                                                                random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.9395933014354066\n",
      "TF-IDF Vectorizer Accuracy Score 0.6495215311004785\n",
      "bi-gram Vectorizer Accuracy Score 0.9395933014354066\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',nb.score(x_test,y_test))\n",
    "nb.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',nb.score(tf_x_test,tf_y_test))\n",
    "nb.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',nb.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.9389952153110048\n",
      "TF-IDF Vectorizer Accuracy Score 0.9449760765550239\n",
      "bi-gram Vectorizer Accuracy Score 0.9389952153110048\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',nb.score(x_test,y_test))\n",
    "nb.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',nb.score(tf_x_test,tf_y_test))\n",
    "nb.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',nb.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.9389952153110048\n",
      "TF-IDF Vectorizer Accuracy Score 0.965311004784689\n",
      "bi-gram Vectorizer Accuracy Score 0.9389952153110048\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',nb.score(x_test,y_test))\n",
    "nb.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',nb.score(tf_x_test,tf_y_test))\n",
    "nb.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',nb.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.937799043062201\n",
      "TF-IDF Vectorizer Accuracy Score 0.9659090909090909\n",
      "bi-gram Vectorizer Accuracy Score 0.937799043062201\n",
      "CPU times: user 1.44 s, sys: 16.7 ms, total: 1.46 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svmmodel = svm.SVC(kernel='linear', C = 1)\n",
    "svmmodel.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',svmmodel.score(x_test,y_test))\n",
    "svmmodel.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',svmmodel.score(tf_x_test,tf_y_test))\n",
    "svmmodel.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',svmmodel.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer Accuracy Score 0.9659090909090909\n"
     ]
    }
   ],
   "source": [
    "svmmodel = svm.SVC(kernel='linear', C = 1)\n",
    "svmmodel.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',svmmodel.score(tf_x_test,tf_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.9264354066985646\n",
      "TF-IDF Vectorizer Accuracy Score 0.6602870813397129\n",
      "bi-gram Vectorizer Accuracy Score 0.9264354066985646\n",
      "CPU times: user 782 ms, sys: 18.6 ms, total: 801 ms\n",
      "Wall time: 729 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "logit.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',logit.score(x_test,y_test))\n",
    "svmmodel.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',logit.score(tf_x_test,tf_y_test))\n",
    "svmmodel.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',logit.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.9043062200956937\n",
      "TF-IDF Vectorizer Accuracy Score 0.7625598086124402\n",
      "bi-gram Vectorizer Accuracy Score 0.9043062200956937\n",
      "CPU times: user 1.05 s, sys: 25.7 ms, total: 1.08 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = GradientBoostingClassifier(n_estimators=50)\n",
    "clf.fit(x_train, y_train)\n",
    "print('CountVectorizer Accuracy Score',clf.score(x_test,y_test))\n",
    "svmmodel.fit(tf_x_train, tf_y_train)\n",
    "print('TF-IDF Vectorizer Accuracy Score',clf.score(tf_x_test,tf_y_test))\n",
    "svmmodel.fit(gm_x_train, gm_y_train)\n",
    "print('bi-gram Vectorizer Accuracy Score',clf.score(gm_x_test,gm_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for article in data[\"Message\"]:\n",
    "    article = re.sub(\"[^a-zA-Z]\",\" \",article)\n",
    "    article = article.lower() \n",
    "    cutWords = [k for k in word_tokenize(article) if k not in stopword_list]\n",
    "    cutWords = [ lemma.lemmatize(word) for word in cutWords]\n",
    "    description_list.append(cutWords)\n",
    "#description_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVector_v2(cutWords, word2vec_model):\n",
    "    vector_list = [word2vec_model[k] for k in cutWords if k in word2vec_model]\n",
    "    vector_df = pd.DataFrame(vector_list)\n",
    "    cutWord_vector = vector_df.mean(axis=0).values\n",
    "    return cutWord_vector\n",
    "\n",
    "word2vec_model = Word2Vec(description_list, size=100, iter=10, min_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_list = []\n",
    "for c in description_list:\n",
    "    vec = getVector_v2(c, word2vec_model)\n",
    "    vector_list.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(vector_list)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[\"Category\"]\n",
    "Y = pd.DataFrame(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean())\n",
    "Y = Y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.7936602870813397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1292  163\n",
       "1   182   35"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, Y, test_size=0.3)\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(train_X, train_y)\n",
    "y_predict = logistic_model.predict(test_X)\n",
    "\n",
    "print('CountVectorizer Accuracy Score',accuracy_score(y_test, y_predict))\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Accuracy Score 0.7876794258373205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1276</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1276  179\n",
       "1   176   41"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=50)\n",
    "gbdt = clf.fit(train_X, train_y)\n",
    "y_predict = gbdt.predict(test_X)\n",
    "print('CountVectorizer Accuracy Score',accuracy_score(y_test, y_predict))\n",
    "pd.DataFrame(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert-TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this notebook: <https://www.kaggle.com/rikdifos/bert-test>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}